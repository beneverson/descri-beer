{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment w/ pre-trained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pre-trained fastText word vectors\n",
    "en_model = KeyedVectors.load_word2vec_format('../data/raw/wiki.en.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: hoppybunny, Similarity: 0.62\n",
      "Word: drinky, Similarity: 0.58\n",
      "Word: hoppity, Similarity: 0.57\n",
      "Word: hoppyland, Similarity: 0.55\n",
      "Word: woppy, Similarity: 0.55\n",
      "Word: malty, Similarity: 0.55\n",
      "Word: cuddlesome, Similarity: 0.54\n",
      "Word: nutty, Similarity: 0.54\n",
      "Word: bunny, Similarity: 0.53\n",
      "Word: chuggy, Similarity: 0.53\n"
     ]
    }
   ],
   "source": [
    "# Pick a word \n",
    "find_similar_to = 'hoppy'\n",
    "\n",
    "# Finding out similar words [default= top 10]\n",
    "for similar_word in en_model.similar_by_word(find_similar_to):\n",
    "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
    "        similar_word[0], similar_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : chopped , Similarity: 0.62\n",
      "Word : dried , Similarity: 0.62\n",
      "Word : cutting , Similarity: 0.61\n",
      "Word : peeled , Similarity: 0.61\n",
      "Word : dirt/grass , Similarity: 0.60\n",
      "Word : stubbled , Similarity: 0.59\n",
      "Word : oniongrass , Similarity: 0.59\n",
      "Word : saltgrass , Similarity: 0.59\n",
      "Word : watered , Similarity: 0.59\n",
      "Word : unsprouted , Similarity: 0.59\n"
     ]
    }
   ],
   "source": [
    "# Test words \n",
    "word_add = ['fresh', 'cut', 'grass']\n",
    "word_sub = None\n",
    "\n",
    "# Word vector addition and subtraction \n",
    "for resultant_word in en_model.most_similar(\n",
    "    positive=word_add, \n",
    "#     negative=word_sub\n",
    "):\n",
    "    print(\"Word : {0} , Similarity: {1:.2f}\".format(\n",
    "        resultant_word[0], resultant_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at occurrence of descriptors in reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys; sys.path.append('..')\n",
    "from beer import descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/miniconda3/lib/python3.4/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read reviews df\n",
    "df = pd.read_csv('../data/interim/ratebeer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review = df['review/text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'caramel', 'cloudy', 'grapefruit', 'light', 'medium', 'orange', 'white'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(review.lower().split()) & set(descriptors.all_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_descriptors = df['review/text'].apply(lambda rev: 1 if len(set(str(rev).lower().split()) & \n",
    "                                                             set(descriptors.all_descriptors)) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8050529330957269"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what fraction of reviews contain at least one descriptor?\n",
    "review_descriptors.sum()/review_descriptors.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with descriptor/beer collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first construct the training data: 'users' are queries, 'items' are beers, \n",
    "# and 'ratings' are average overall ratings among all reviews of beer i that contain descriptor j\n",
    "#\n",
    "# first get all descriptors in each review\n",
    "df['descriptors'] = df['review/text'].apply(lambda r: list(set(str(r).lower().split()) & \n",
    "                                                           set(descriptors.all_descriptors)))\n",
    "# create a new row for each element in the descriptors list\n",
    "s = df.apply(lambda x: pd.Series(x['descriptors']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'descriptor'\n",
    "df_extended = df.join(s)\n",
    "# convert the score to the appropriate type\n",
    "df_extended['score'] = df_extended['review/overall'].apply(lambda s: int(s.split('/')[0]))\n",
    "# group by beer and descriptor, compute average score\n",
    "beer_desc_score = df_extended.groupby(['beer/beerId', 'descriptor'])['score'].mean()\n",
    "# persist the data\n",
    "beer_desc_score.reset_index().to_csv('../data/interim/beer_desc_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 1.5890\n",
      "MAE:  1.1212\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 1.5945\n",
      "MAE:  1.1252\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 1.5949\n",
      "MAE:  1.1239\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 1.5909\n",
      "MAE:  1.1241\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 1.5923\n",
      "MAE:  1.1223\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 1.5923\n",
      "Mean MAE : 1.1233\n",
      "------------\n",
      "------------\n",
      "        Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    \n",
      "MAE     1.1212  1.1252  1.1239  1.1241  1.1223  1.1233  \n",
      "RMSE    1.5890  1.5945  1.5949  1.5909  1.5923  1.5923  \n"
     ]
    }
   ],
   "source": [
    "# next, train a simple out-of-the-box CF model on the data\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise import evaluate, print_perf\n",
    "\n",
    "ratings_df = beer_desc_score.reset_index()[['descriptor', 'beer/beerId', 'score']]\n",
    "\n",
    "# create a Reader and Dataset (surprise)\n",
    "reader = Reader(rating_scale=(1, 20))\n",
    "data = Dataset.load_from_df(ratings_df, reader)\n",
    "data.split(5)\n",
    "# run the algorithm\n",
    "algo = SVD()\n",
    " # evaluate performances\n",
    "perf = evaluate(algo, data, measures=['RMSE', 'MAE'])\n",
    "# print results\n",
    "print_perf(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NormalPredictor.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 3.6319\n",
      "MAE:  2.8514\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 3.6368\n",
      "MAE:  2.8547\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 3.6406\n",
      "MAE:  2.8571\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 3.6351\n",
      "MAE:  2.8549\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 3.6394\n",
      "MAE:  2.8568\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 3.6368\n",
      "Mean MAE : 2.8550\n",
      "------------\n",
      "------------\n",
      "        Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    \n",
      "MAE     2.8514  2.8547  2.8571  2.8549  2.8568  2.8550  \n",
      "RMSE    3.6319  3.6368  3.6406  3.6351  3.6394  3.6368  \n"
     ]
    }
   ],
   "source": [
    "from surprise import NormalPredictor\n",
    "# run the algorithm\n",
    "algo = NormalPredictor()\n",
    " # evaluate performances\n",
    "perf = evaluate(algo, data, measures=['RMSE', 'MAE'])\n",
    "# print results\n",
    "print_perf(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigstr = '\\n'.join([str(s).lower() for s in df['review/text'].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "translator = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigstr_nopunc = bigstr.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/interim/reviews_raw.txt', 'w+') as f:\n",
    "    f.write(bigstr_nopunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/raw/beerdf.pandas\", \"rb\") as f:\n",
    "    other_reviews = pickle.load(f, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "otherbigstr ='\\n'.join([str(s).lower() for s in other_reviews['review/text'].tolist()])\n",
    "otherbigstr_nopunc = otherbigstr.translate(translator)\n",
    "\n",
    "with open('../data/interim/reviews_raw.txt', 'a') as f:\n",
    "    f.write(otherbigstr_nopunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
